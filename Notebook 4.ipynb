{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Initiation à la programmation (Python)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compter les mots dans un texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  0 Nombre de lignes\n",
    "### Exercice 1\n",
    "Compter le nombre de lignes dans la version obtenue sur [Gutenberg.org](http://www.gutenberg.org) de [*De l'Origine des Espèces*](http://www.gutenberg.org/ebooks/14158). Il s'agit du fichier DeLOrigine.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Première estimation du combre de mots\n",
    "La définition de ce qu'est un mot n'est pas triviale. Commençons avec une première définition : un mot est une chaîne de caractères délimitée par des espaces et/ou des retours à ligne.\n",
    "### Exercice 2\n",
    "Compter le nombre de mots dans *De l'Origine des Espèces* selon cette première définition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-11T16:19:28.681891Z",
     "start_time": "2017-12-11T16:19:28.677575Z"
    }
   },
   "source": [
    "Cette première définition du mot, une chaîne de caractères entre deux espaces blancs pose plusieurs problèmes. Lesquels ? \n",
    "\n",
    "### Exercice 3\n",
    "Afin de se faire une idée peut-être plus précise de ces problèmes, construire une liste contenant tous les mots, c'est-à-dire une liste de 220166 éléments. En afficher les élements entre les indices 6000 et 6050. On peut acceder aux éléments d'une liste `l` compris entre les indices `a` et `b` avec :\n",
    "```python\n",
    "l[a:b]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T09:52:58.561747Z",
     "start_time": "2017-12-12T09:52:58.558691Z"
    }
   },
   "source": [
    "## 2 Tokeniser un texte\n",
    "En traitement automatique des langues, discipline à l'intersection d'informatique et de la linguistique, l'opération qui consiste à découper un texte en mots s'appelle la **tokenisation**. D'ailleurs, plutôt que de mots, on parle de **tokens**. Le terme **mot** désigne les entités abstraites qui se réalisent dans les tokens. \n",
    "\n",
    "Le texte *le chat dort sur le canapé* compte 6 tokens et 5 mots. Le mot *le* a deux occurrences, les autres une seule.\n",
    "\n",
    "Un algorithme de tokenisation est une opérationnalisation d'une définition d'un mot. On pourrait construire un tel algorithme, mais d'autres l'ont déjà fait pour nous !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T09:19:10.572253Z",
     "start_time": "2017-12-13T09:19:09.252119Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'instruction ci-dessus importe la package (ou librairie ou bibliothèque) nommée [nltk](http://www.nltk.org).  Un package est une collection de 'fonctions' qui étendent les fonctionnalités de Python (le mécanisme existe dans la plupart des langages de programmation).  \n",
    "\n",
    "Python fournit un certain nombre de [packages par défaut](https://docs.python.org/3/library/index.html), et l'on peut par ailleurs en installer d'[autres](https://pypi.python.org/pypi). Anaconda, la distribution de Python que l'on utilise, installe en même temps que Python [plus 200 autres packages](https://docs.anaconda.com/anaconda/packages/py3.6_win-64), dont nltk. \n",
    "\n",
    "Nltk propose plusieurs tokenisers. Nous allons utiliser celui qui s'appelle WordPunctTokenizer, qui prend en compte la ponctuation pour délimiter les mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T09:19:10.584653Z",
     "start_time": "2017-12-13T09:19:10.573811Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "tokenizer.tokenize(\"le chat dort sur le canapé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4\n",
    "Tokeniser le texte \"Parce qu'aujoud'hui on a cours de Python, c'est la fête !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5\n",
    "Compter le nombre de tokens dans *De l'Origine des Espèces*. C'est possible en une seule ligne ! Indice, on peut lire un fichier dans une chaîne de caractères de la manière suivante :\n",
    "```pytohn\n",
    "open('nomDuFichier.txt').read()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T10:36:49.328209Z",
     "start_time": "2017-12-12T10:36:49.323282Z"
    }
   },
   "source": [
    "## Comptage de la fréquence de mots dans un texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T10:37:23.935976Z",
     "start_time": "2017-12-12T10:37:23.932158Z"
    }
   },
   "source": [
    "### Exercice 6\n",
    "A votre avis, combien de fois apparait le mot *le* ? Le mot *livre* ? Quel est le mot le plus fréquent ? Combien y a-t-il de mots ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 7\n",
    "Compter le nombre d'occurrences des mots *le* et *livre*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 8\n",
    "Construire un dictionnaire qui donne le nombre d'occurrences de chaque mot du texte. \n",
    "```python\n",
    "print(nOccurrences['espèce'])\n",
    "594\n",
    "```\n",
    "Combien y a-t-il de mots dans le texte ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 9\n",
    "Que fait le programme suivant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T09:19:10.724794Z",
     "start_time": "2017-12-13T09:19:10.588413Z"
    }
   },
   "outputs": [],
   "source": [
    "l=[]\n",
    "for mot in nOccurrences:\n",
    "    l.append([nOccurrences[mot],mot])\n",
    "l.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T10:48:18.815326Z",
     "start_time": "2017-12-12T10:48:18.812015Z"
    }
   },
   "source": [
    "### Exercice 10\n",
    "Combien de mots n'apparaissent qu'une seule fois (on appelle ces mots des *hapax*, ou *hapax legomenon*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T10:56:03.578649Z",
     "start_time": "2017-12-12T10:56:03.575575Z"
    }
   },
   "source": [
    "### Exercice 11\n",
    "Quel pourcentage de tokens représentent les 10 mots les plus fréquents ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue\n",
    "Les 10 mots les plus fréquents représentent 28% des tokens. A l'inverse, les 5567 mots les plus rares, qui n'apparaissent qu'une seule fois, représentent 0.02% des tokens. Dit autrement, les 0.0007% de mots les plus fréquents couvrent 28% du texte, tandis que les 42% les plus rares couvrent 0.02% du texte. **Il y a très peu de mots très fréquents, énormément de mots très rares**.\n",
    "\n",
    "D'une manière générale, dans un texte, si l'on classe les mots du plus fréquent au plus rare, le second est (de l'ordre de) 2 fois moins fréquent que le premier, le 3ème 3 fois moins fréquent que le premier, le 4ème 4 fois moins fréquent que le 1er...\n",
    "\n",
    "On peut essayer de le vérfier pour l'origine des espèces :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T09:19:10.725139Z",
     "start_time": "2017-12-13T08:19:09.238Z"
    }
   },
   "outputs": [],
   "source": [
    "freqObservées=[]\n",
    "for mot in nOccurrences:\n",
    "    freqObservées.append([nOccurrences[mot]])\n",
    "l.sort(reverse=True) #reverse=True indique qu'il faut trier dans l'ordre décroissant, le mot le plus fréquent en premier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T09:19:10.725449Z",
     "start_time": "2017-12-13T08:19:09.242Z"
    }
   },
   "outputs": [],
   "source": [
    "freqAttendue=[]\n",
    "for i in range(0,len(freq)):\n",
    "    freqAttendue.append(freq[0]/(i+1)) #on s'attend a ce que le n-ème mot (d'indice i-1) soit n fois moins fréquent que le premier (donc i+1 fois moins fréquent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T09:19:10.725660Z",
     "start_time": "2017-12-13T08:19:09.244Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #matplotlib est une librairie pour tracer des figures ; la ligne suivante indique qu'il faut tracer les figures dans le notebook directement (plutot que dans une autre fenêtre, ou dans un fichier,...)\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T09:19:10.725856Z",
     "start_time": "2017-12-13T08:19:09.247Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(freq,'.')\n",
    "plt.plot(freqAttendue,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ne vois pas grand chose ! Les mots les plus fréquents sont de l'ordre de 10000 fois plus fréquents que les plus rares. Ces fortes différence de fréquence, de 1 à 10000, ne sont pas visualisables.\n",
    "\n",
    "Pour contourner cette difficulté, on utilise des échelles logarithmiques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T09:19:10.726040Z",
     "start_time": "2017-12-13T08:19:09.250Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.loglog(freq,'.')\n",
    "plt.loglog(freqAttendue,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La correspondance n'est pas parfaite, l'approximation n'est pas absurde non plus.\n",
    "\n",
    "La manière dont les fréquences se distribuent s'appelle la [loi de Zipf](https://fr.wikipedia.org/wiki/Loi_de_Zipf), du nom du linguiste qui l'a (re)découverte, George Kingsley Zipf, en 1936."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
